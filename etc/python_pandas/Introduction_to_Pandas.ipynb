{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "![pandas](http://pandas.pydata.org/_static/pandas_logo.png)\n",
    "**Pandas** is an open source Python library for complex, tabular datasets data analysis.\n",
    "\n",
    "**Features**\n",
    "- Defines **tabular data types**: database-like tables, with labelled rows and columns\n",
    "- **Data consolidation and data integration**: remove duplicates, clean data, manage missing values: automatically align tables by index\n",
    "- **Summarization**: create \"pivot\" tables\n",
    "- **In-memory, SQL-like operations**: join, aggregate (group by)\n",
    "- Very flexible **import/export** data\n",
    "- **Date and time** handling built-in including timezones\n",
    "- **Easy visualization** based on Matplotlib\n",
    "\n",
    "In Pandas, it introduces two new data structures to Python - `Series` and `DataFrame`, both of which are built on top of `NumPy` (this means it's fast).\n",
    "\n",
    "**Online resources**\n",
    "\n",
    "The Pandas development community maintains an extensive online documentation system, including user guides and tutorials, at:\n",
    "http://pandas.pydata.org/\n",
    "\n",
    "**Importing the Pandas module**\n",
    "\n",
    "There are several ways to import Pandas. The standard approach is to use a simple import statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for large amounts of calls to Pandas functions, it can become tedious to write `pandas.X` over and over again. Instead, it is common to import under the briefer name `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statement will allow us to access Pandas objects using `pd.X` instead of `pandas.X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to limit the display of rows of datasets\n",
    "from pandas import set_option\n",
    "set_option(\"display.max.rows\",16)\n",
    "\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "A Series is a one-dimensional object similar to an array, list, or column in a table. It will assign a labeled index to each item in the Series. By default, each item will receive an index label from 0 to N, where N is the length of the Series minus one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a Series with an arbitrary list\n",
    "s = pd.Series([10, 'Durian', 10.18, -2025678982, 'Selamat Hari Raya!'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can specify an index to use when creating the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = pd.Series([10, 'Durian', 10.18, -2025678982, 'Selamat Hari Raya!'], index=[15,20,25,30,35])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the index to select specific items from the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Series constructor can convert a dictonary as well, using the keys of the dictionary as its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = {'Kuala Lumpur': 4321, 'Banting': 278, 'Klang': 64, 'Cyberjaya': 33,\n",
    "     'Kajang': 86}\n",
    "dengue=pd.Series(e)\n",
    "dengue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display cities with dengue cases more than 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result will be in the form of True/False\n",
    "dengue>50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show the cities names\n",
    "dengue[dengue>50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change the values in a Series on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (dengue['Banting'])\n",
    "\n",
    "#change the number of dengue cases for Banting to 350\n",
    "\n",
    "dengue['Banting']=350\n",
    "print (dengue['Banting'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe\n",
    "\n",
    "A DataFrame is a tablular data structure comprised of rows and columns which is similiar to a spreadsheet, database table, or R's data.frame object. For Pandas, a DataFrame is a group of Series objects that share an index (the column names).\n",
    "\n",
    "### Reading Data\n",
    "\n",
    "To create a DataFrame out of common Python data structures, we can pass a dictionary of lists to the DataFrame constructor.\n",
    "\n",
    "Using the columns parameter allows us to tell the constructor how we'd like the columns ordered. By default, the DataFrame constructor will order the columns alphabetically (though this isn't the case when reading from a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {'year': [2010, 2011, 2012, 2011, 2012, 2010, 2011, 2012],\n",
    "        'team': ['Arsenal', 'Arsenal', 'Arsenal', 'Liverpool', 'Liverpool', 'Liverpool', 'Spurs', 'Spurs'],\n",
    "        'wins': [13, 9, 7, 12, 14, 5, 7, 8],\n",
    "        'losses': [2, 4, 2, 10, 15, 8, 11, 12]}\n",
    "football=pd.DataFrame(data)\n",
    "football"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#order the columns according to 'year', 'team', 'wins' and 'losses'\n",
    "football=pd.DataFrame(data, columns=['year', 'team', 'wins','losses'])\n",
    "football"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CSV\n",
    "\n",
    "Reading a CSV is as simple as calling the `read_csv` function. By default, the read_csv function expects the column separator to be a comma, but you can change that using the `sep` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find out more about read_csv\n",
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read from iris datasets\n",
    "iris=pd.read_csv('data/iris.csv')\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show the first 5 rows of iris\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show the last 5 rows of iris\n",
    "iris.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "plt.hist(iris.petal_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv from the Internet URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read Apple historical share prices from Google Finance\n",
    "apple=pd.read_csv(\"http://www.google.com/finance/historical?q=NASDAQ%3AAAPL&ei=NHKyV6nsHcWsugSomoS4Ag&output=csv\")\n",
    "apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#summary of apple DataFrame\n",
    "apple.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#describe method for seeing basic statistics about the dataset's numeric columns.\n",
    "apple.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show the dimension of apple\n",
    "apple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data type for apple\n",
    "type(apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data type for column Volume\n",
    "print(apple.Volume.dtype)\n",
    "print(apple['High'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting\n",
    "\n",
    "You can think of a DataFrame as a group of Series that share an index (in this case the column headers). This makes it easy to select specific columns.\n",
    "\n",
    "Selecting a single column from the DataFrame will return a Series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select the top 5 rows for Low\n",
    "apple.Low.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select the last 5 rows for Volume\n",
    "apple['Volume'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorting by Volume\n",
    "apple.sort_values(['Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shares where Close > 90\n",
    "apple[apple.Close > 90].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1:\n",
    "\n",
    "- Display top 6 rows of all shares where `Close` prices > than `100` OR `Volume` < 1500000 for `apple`\n",
    "- Display all shares where `High` prices is between `100` and `110` for `apple`\n",
    "- Display the mean/min/max/median/sum `Close` price for `apple`\n",
    "- Find shares where `Low` >100 and sort according to `Close` price and `Volume` (descending) for `apple`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 1:answer 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 1:answer 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 1:answer 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 1:answer 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "pandas primarily uses the value `np.nan` to represent missing data. It is by default not included in computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a simple dataframe\n",
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f', 'h'],columns=['one', 'two', 'three'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add in a new column 'four'\n",
    "df['four']='Bar'\n",
    "#add in another new column 'five'\n",
    "df['five']=df['one']>1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reindex dataframe df and assign to df2\n",
    "df2 = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by Label\n",
    ".loc can be used for index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show row with lable index 'a'\n",
    "df.loc['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2\n",
    "\n",
    "- Display row for index 'a', 'e' and 'h'\n",
    "- Display row from index 'e' to 'h'\n",
    "- Display all data in reverse order using .loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 2:answer 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 2:answer 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 2:answer 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values considered “missing”\n",
    "\n",
    "As data comes in many shapes and forms, pandas aims to be flexible with regard to handling missing data. While `NaN` is the default missing value marker for reasons of computational speed and convenience, we need to be able to easily detect this value with data of different types: `floating point`, `integer`, `boolean`, and `general object`. In many cases, however, the Python None will arise and we wish to also consider that “missing” or “null”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check if null exist\n",
    "pd.isnull(df2['one']) #df2.one.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To drop any rows that have missing data\n",
    "df2.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace missing value\n",
    "df2.four.fillna(value='Foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace all missing value\n",
    "df2.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by\n",
    "\n",
    "By “group by”, it is referring to a process involving one or more of the following steps\n",
    "\n",
    "- **Splitting** the data into groups based on some criteria\n",
    "- **Applying** a function to each group independently\n",
    "- **Combining** the results into a data structure\n",
    "\n",
    "The name GroupBy should be quite familiar to those who have used a SQL-based tool (or itertools), in which you can write code like:\n",
    "\n",
    "```{sql}\n",
    "SELECT Column1, Column2, mean(Column3), sum(Column4)\n",
    "FROM SomeTable\n",
    "GROUP BY Column1, Column2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find mean for all `sepal_length`, `sepal_width`, `petal_length` and `petal_width` by `species`\n",
    "iris.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find mean for all `sepal_length` by `species`\n",
    "iris['sepal_length'].groupby(iris.species).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 3:\n",
    "\n",
    "- Read the TradeOffData.csv dataset\n",
    "- Provide summary of the dataset\n",
    "- split the dataset according to 'Group' and 'Treatment'\n",
    "- By using the 'aggregate' method, get the sum for each 'Group' and 'Treatment' for 'RelativeFitness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 3: answer 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 3:answer 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 3:answer 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quiz 3:answer 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge, join, and concatenate¶\n",
    "pandas provides various facilities for easily combining together Series, DataFrame, and Panel objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.\n",
    "\n",
    "<img src=\"files/merge_join.png\", width=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dataframe df_a\n",
    "df_a = pd.DataFrame(\n",
    "    {'subject_id': ['1', '2', '3', '4', '5'],\n",
    "     'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n",
    "      'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}, \n",
    "       columns = ['subject_id', 'first_name', 'last_name'])\n",
    "\n",
    "#create dataframe df_b\n",
    "df_b=pd.DataFrame(\n",
    "         {'subject_id': ['4', '5', '6', '7', '8'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']},\n",
    "         columns = ['subject_id', 'first_name', 'last_name'])\n",
    "\n",
    "#create dataframe df_n\n",
    "df_n = pd.DataFrame(\n",
    "        {'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}, columns = ['subject_id','test_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/data_frame.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join the two dataframes along row\n",
    "df_new=pd.concat([df_a,df_b])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join the two dataframes along column\n",
    "pd.concat([df_a, df_b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Merge two dataframes along the subject_id value\n",
    "pd.merge(df_new, df_n, on='subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Merge two dataframes with both the left and right dataframes using the subject_id key\n",
    "pd.merge(df_new, df_n, left_on='subject_id', right_on='subject_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with outer join\n",
    "\n",
    "\"Full outer join produces the set of all records in Table A and Table B, with matching records from both sides where available. If there is no match, the missing side will contain null.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Merge with outer join\n",
    "pd.merge(df_a, df_b, on='subject_id', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with inner join\n",
    "\n",
    "\"Inner join produces only the set of records that match in both Table A and Table B.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Merge with inner join\n",
    "pd.merge(df_a, df_b, on='subject_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Merge with right join\n",
    "pd.merge(df_a, df_b, on='subject_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Merge with left join\n",
    "pd.merge(df_a, df_b, on='subject_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author** : [Poo Kuan Hoong](http://www.linkedin.com/in/kuanhoong)\n",
    "\n",
    "**Credits**: [Intro to Pandas Data Structures](http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/), [Brandon’s Pandas Tutorial](https://github.com/brandon-rhodes/pycon-pandas-tutorial), [ SciPy2016 tutorial: Analyzing and Manipulating Data with Pandas](https://github.com/jonathanrocher/pandas_tutorial), [Pandas Documentation](http://pandas.pydata.org/pandas-docs/stable/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
